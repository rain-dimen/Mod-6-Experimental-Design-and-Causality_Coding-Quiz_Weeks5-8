{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04b2554e",
   "metadata": {},
   "source": [
    "# Mod 6 Homework Reflections \n",
    "# Weeks 5-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa913016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting statsmodels\n",
      "  Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (1.16.0)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (2.3.1)\n",
      "Collecting patsy>=0.5.6 (from statsmodels)\n",
      "  Downloading patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/codespace/.local/lib/python3.12/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/codespace/.local/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/codespace/.local/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "Downloading statsmodels-0.14.5-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
      "Installing collected packages: patsy, statsmodels\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [statsmodels]\u001b[0m [statsmodels]\n",
      "\u001b[1A\u001b[2KSuccessfully installed patsy-1.0.1 statsmodels-0.14.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5ccdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb5b35d-d0f3-4154-b67e-185ba285484b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baed688",
   "metadata": {},
   "source": [
    "# Week 5 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b323dddb",
   "metadata": {},
   "source": [
    "1. Draw a diagram for the following negative feedback loop:\n",
    "\n",
    "Sweating causes body temperature to decrease.  High body temperature causes sweating.\n",
    "\n",
    "A negative feedback loop means that one thing increases another while the second thing decreases the first.\n",
    "\n",
    "Remember that we are using directed acyclic graphs where two things cannot directly cause each other.\n",
    "\n",
    "2. Describe an example of a positive feedback loop.  This means that one things increases another while the second things also increases the first.\n",
    "\n",
    "3. Draw a diagram for the following situation:\n",
    "\n",
    "Lightning storms frighten away deer and bears, decreasing their population, and cause flowers to grow, increasing their population.\n",
    "Bears eat deer, decreasing their population.\n",
    "Deer eat flowers, decreasing their population.\n",
    "\n",
    "Write a dataset that simulates this situation.  (Show the code.) Include noise / randomness in all cases.\n",
    "\n",
    "Identify a backdoor path with one or more confounders for the relationship between deer and flowers.\n",
    "\n",
    "4. Draw a diagram for a situation of your own invention.  The diagram should include at least four nodes, one confounder, and one collider.  Be sure that it is acyclic (no loops).  Which node would say is most like a treatment (X)?  Which is most like an outcome (Y)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df460110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   lightning      bears       deer    flowers\n",
      "0   5.993428  56.683461  40.024597  57.853220\n",
      "1   4.723471  71.759312  39.478018  46.398948\n",
      "2   6.295377  42.644146  36.028023  53.076502\n",
      "3   8.046060  38.446368  25.001107  69.666813\n",
      "4   4.531693  60.493241  42.684678  45.933511\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "# Simulating the data \n",
    "\n",
    "np.random.seed(42)  \n",
    "n = 500  # observations\n",
    "\n",
    "# Exogenous variable: Lightning storms, frequency/intensity \n",
    "lightning = np.random.normal(5, 2, n)\n",
    "\n",
    "# Bears are frightened away by lightning\n",
    "bears = 100 - 8 * lightning + np.random.normal(0, 5, n)\n",
    "\n",
    "# Deer are frightened by lightning and eaten by bears\n",
    "deer = 80 - 5 * lightning - 0.3 * bears + np.random.normal(0, 5, n)\n",
    "\n",
    "# Flowers: grow more with lightning, eaten by deer\n",
    "flowers = 50 + 4 * lightning - 0.5 * deer + np.random.normal(0, 5, n)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"lightning\": lightning,\n",
    "    \"bears\": bears,\n",
    "    \"deer\": deer,\n",
    "    \"flowers\": flowers\n",
    "})\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34998ee4",
   "metadata": {},
   "source": [
    "# Week 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee53e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Treatment Effect (ATE): 1.6979\n",
      "Average Treatment Effect on Treated (ATT): 1.8464\n",
      "Average Treatment Effect on Untreated (ATU): 1.5495\n",
      "Naive Optimal Treatment Effect (max): 2.1725\n",
      "Robust Marginal Treatment Effect (90th percentile): 1.9280\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "df6 = pd.read_csv(\"homework_6.1.csv\")\n",
    "\n",
    "# Create treated and untreated groups\n",
    "treated = df6[df6[\"X\"] == 1].reset_index(drop=True)\n",
    "untreated = df6[df6[\"X\"] == 0].reset_index(drop=True)\n",
    "\n",
    "# Define nearest-neighbor match function\n",
    "def nearest_match(source, target):\n",
    "    nn = NearestNeighbors(n_neighbors=1)\n",
    "    nn.fit(target[[\"Z\"]])\n",
    "    distances, indices = nn.kneighbors(source[[\"Z\"]])\n",
    "    return indices.flatten()\n",
    "\n",
    "# Match treated to untreated and untreated to treated\n",
    "treated_to_untreated_idx = nearest_match(treated, untreated)\n",
    "untreated_to_treated_idx = nearest_match(untreated, treated)\n",
    "\n",
    "# Generate counterfactual outcomes\n",
    "treated[\"Y_cf\"] = untreated.loc[treated_to_untreated_idx, \"Y\"].values\n",
    "untreated[\"Y_cf\"] = treated.loc[untreated_to_treated_idx, \"Y\"].values\n",
    "\n",
    "# Compute treatment effects\n",
    "treated[\"TE\"] = treated[\"Y\"] - treated[\"Y_cf\"]\n",
    "untreated[\"TE\"] = treated.loc[untreated_to_treated_idx, \"Y\"].values - untreated[\"Y\"]\n",
    "\n",
    "# Compute average treatment effects\n",
    "ate = (treated[\"TE\"].mean() + untreated[\"TE\"].mean()) / 2\n",
    "att = treated[\"TE\"].mean()\n",
    "atu = untreated[\"TE\"].mean()\n",
    "\n",
    "# Compute Optimal Treatment Effect (max) and MTE using the 90th percentile\n",
    "optimal_te = untreated[\"TE\"].max()\n",
    "MTE_90th = np.percentile(untreated[\"TE\"], 90)\n",
    "\n",
    "# Print results\n",
    "print(f\"Average Treatment Effect (ATE): {ate:.4f}\")\n",
    "print(f\"Average Treatment Effect on Treated (ATT): {att:.4f}\")\n",
    "print(f\"Average Treatment Effect on Untreated (ATU): {atu:.4f}\")\n",
    "print(f\"Naive Optimal Treatment Effect (max): {optimal_te:.4f}\")\n",
    "print(f\"Robust Marginal Treatment Effect (90th percentile): {MTE_90th:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6478f6",
   "metadata": {},
   "source": [
    "# Week 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de9bd3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True effect of X on Y: 2.0\n",
      "Without Confounder W: 3.510405682088037\n",
      "With Confounder W: 1.9981919455639527\n"
     ]
    }
   ],
   "source": [
    "# Week 7, Question 1\n",
    "\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "np.random.seed(0)\n",
    "n = 1000\n",
    "\n",
    "# Confounder\n",
    "W = np.random.normal(0, 1, n)\n",
    "\n",
    "# Treatment\n",
    "X = W + np.random.normal(0, 1, n)\n",
    "\n",
    "# Outcome\n",
    "Y = 2*X + 3*W + np.random.normal(0, 1, n)\n",
    "\n",
    "# Regress Y and X - no confounder)\n",
    "model_no_conf = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "\n",
    "# Regress Y and X - including confounder\n",
    "model_full = sm.OLS(Y, sm.add_constant(np.column_stack([X, W]))).fit()\n",
    "\n",
    "print(\"True effect of X on Y: 2.0\")\n",
    "print(\"Without Confounder W:\", model_no_conf.params[1])\n",
    "print(\"With Confounder W:\", model_full.params[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05a1bb61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smallest p-value for W: 0.002831\n",
      "Number of times p < 0.05: 51 out of 1000\n"
     ]
    }
   ],
   "source": [
    "# Week 7, Question 2\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "p_values = []  \n",
    "\n",
    "for i in range(1000):\n",
    "    n = 200  # number of data points\n",
    "\n",
    "    W = np.random.normal(0, 1, n)\n",
    "    X = np.random.normal(0, 1, n)\n",
    "    error = np.random.normal(0, 1, n)\n",
    "\n",
    "    # true model, coeff of W is 0\n",
    "    Y = 2 * X + error  \n",
    "\n",
    "    # regression: including X and W\n",
    "    XW = sm.add_constant(np.column_stack((X, W)))\n",
    "    model = sm.OLS(Y, XW).fit()\n",
    "\n",
    "    # p-value of W is the 3rd value (after constant and X)\n",
    "    p_w = model.pvalues[2]\n",
    "    p_values.append(p_w)\n",
    "\n",
    "# results\n",
    "min_p = np.min(p_values)\n",
    "count_sig = np.sum(np.array(p_values) < 0.05)\n",
    "\n",
    "print(\"Smallest p-value for W:\", round(min_p, 6))\n",
    "print(\"Number of times p < 0.05:\", count_sig, \"out of 1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443a0f8",
   "metadata": {},
   "source": [
    "# Week 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8e1386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>Z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.109218</td>\n",
       "      <td>1.764052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.259504</td>\n",
       "      <td>0.400157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.647584</td>\n",
       "      <td>0.978738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.106071</td>\n",
       "      <td>2.240893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3.583464</td>\n",
       "      <td>1.867558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  X         Y         Z\n",
       "0           0  1  4.109218  1.764052\n",
       "1           1  0  2.259504  0.400157\n",
       "2           2  0 -0.647584  0.978738\n",
       "3           3  0  2.106071  2.240893\n",
       "4           4  1  3.583464  1.867558"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8 = pd.read_csv(\"homework_8.1.csv\")\n",
    "df8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b4d0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE ≈ 2.274\n"
     ]
    }
   ],
   "source": [
    "# Week 8, Question 1\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df8 = pd.read_csv(\"homework_8.1.csv\")\n",
    "\n",
    "Z = df8[[\"Z\"]]\n",
    "X = df8[\"X\"]\n",
    "Y = df8[\"Y\"]\n",
    "\n",
    "log_model = LogisticRegression()\n",
    "log_model.fit(Z, X)\n",
    "\n",
    "P = log_model.predict_proba(Z)[:, 1]\n",
    "\n",
    "# IPW\n",
    "weights = np.where(X == 1, 1 / P, 1 / (1 - P))\n",
    "\n",
    "ATE = (np.sum(weights * (X * Y)) / np.sum(weights * X)) - \\\n",
    "      (np.sum(weights * ((1 - X) * Y)) / np.sum(weights * (1 - X)))\n",
    "\n",
    "print(f\"ATE ≈ {ATE:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565002af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84 0.58 0.71]\n"
     ]
    }
   ],
   "source": [
    "# Question 2\n",
    "\n",
    "print(np.round(P[:3], 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9d8e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATE ≈ 3.44\n"
     ]
    }
   ],
   "source": [
    "# Question 3\n",
    "\n",
    "\n",
    "from scipy.spatial.distance import mahalanobis\n",
    "from numpy.linalg import inv\n",
    "\n",
    "df82 = pd.read_csv(\"homework_8.2.csv\")\n",
    "\n",
    "# treated (X=1), untreated (X=0)\n",
    "treated = df82[df82[\"X\"] == 1].reset_index(drop=True)\n",
    "untreated = df82[df82[\"X\"] == 0].reset_index(drop=True)\n",
    "\n",
    "Z = df82[[\"Z1\", \"Z2\"]].to_numpy()\n",
    "\n",
    "cov_matrix = np.cov(Z, rowvar=False)\n",
    "inv_cov = inv(cov_matrix)\n",
    "\n",
    "# matching using Mahalanobis distance\n",
    "matches = []\n",
    "for i in range(len(treated)):\n",
    "    z_treated = treated.loc[i, [\"Z1\", \"Z2\"]].to_numpy()\n",
    "    distances = [mahalanobis(z_treated, untreated.loc[j, [\"Z1\", \"Z2\"]].to_numpy(), inv_cov)\n",
    "                 for j in range(len(untreated))]\n",
    "    nearest_index = np.argmin(distances)\n",
    "    matches.append(untreated.loc[nearest_index, \"Y\"])\n",
    "\n",
    "treated[\"Y_cf\"] = matches\n",
    "treated[\"TE\"] = treated[\"Y\"] - treated[\"Y_cf\"]\n",
    "\n",
    "ATE = treated[\"TE\"].mean()\n",
    "print(f\"ATE ≈ {ATE:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "298585bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treated item with least common support (exact): (np.float64(2.69622405256358), np.float64(0.5381554886023228))\n",
      "Rounded to match options: (np.float64(2.7), np.float64(0.5))\n",
      "Nearest untreated to that treated (Z1, Z2): (np.float64(1.5199948607657727), np.float64(-1.2822079376259403))\n",
      "Mahalanobis distance to nearest untreated: 1.3830045328325058\n"
     ]
    }
   ],
   "source": [
    "# Question 4\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv, pinv\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "df = pd.read_csv(\"homework_8.2.csv\")\n",
    "\n",
    "treated = df[df[\"X\"] == 1].reset_index(drop=True)\n",
    "untreated = df[df[\"X\"] == 0].reset_index(drop=True)\n",
    "\n",
    "Z_all = df[[\"Z1\", \"Z2\"]].to_numpy()\n",
    "Z_t = treated[[\"Z1\", \"Z2\"]].to_numpy()\n",
    "Z_u = untreated[[\"Z1\", \"Z2\"]].to_numpy()\n",
    "\n",
    "cov = np.cov(Z_all, rowvar=False)\n",
    "VI = pinv(cov)\n",
    "\n",
    "D = cdist(Z_t, Z_u, metric=\"mahalanobis\", VI=VI)\n",
    "\n",
    "nearest_dists = D.min(axis=1)\n",
    "nearest_idxs  = D.argmin(axis=1)\n",
    "\n",
    "i_farthest = int(nearest_dists.argmax())\n",
    "\n",
    "z1, z2 = treated.loc[i_farthest, [\"Z1\", \"Z2\"]].to_numpy()\n",
    "\n",
    "print(\"Treated item with least common support (exact):\", (z1, z2))\n",
    "print(\"Rounded to match options:\", (np.round(z1, 1), np.round(z2, 1)))\n",
    "\n",
    "j_nearest = int(nearest_idxs[i_farthest])\n",
    "z1_u, z2_u = untreated.loc[j_nearest, [\"Z1\", \"Z2\"]].to_numpy()\n",
    "print(\"Nearest untreated to that treated (Z1, Z2):\", (z1_u, z2_u))\n",
    "print(\"Mahalanobis distance to nearest untreated:\", float(nearest_dists[i_farthest]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
